---
layout: post
title: Genetic algorithms for search? 
tags: 
- todo

---

Working as a search engineer myself I decided to [develop a framework](https://github.com/mikolajkania/project-x) for discovering optimal search settings for ElasticSearch and Solr. In this post I'll describe it and briefly discuss how the good process of building the quality of search should look like. Let's start!

<!--excerpt-->

<h2>Problem to solve</h2>

Imagine you are a search engineer or analyst whose responsibility is the *quality of search*. Consider an index of millions of documents, in which every one of them may have many searchable fields. When user types query your ranking system evaluates final score of a document taking into account all of those fields with different weights assigned. It's your job to figure out values, somehow.

<h2>Why is it rocket science?</h2>

With a help of the experts you were able to prepare a list of expected documents for given queries. In advanced systems such a list may easily consist of hundreds of entries. Now, imagine intuitively changing weight of one of those fields, running queries manually and guessing if the results are better and what to do next... nightmare. *You need a process.*  

The first step would be *running all queries* with default settings and checking how the results deviates from expectations. You need an *automatic system* to perform at least the first part of a job and metrics to get initial overview; it may be a percentage score or groups of broken queries. After that and deep analysis, hopefully, you can come up with *patterns of errors* and propose a solution. Then, the solution should be registered, applied and tested again. It should be done until results cannot be improved.  


<h2>Sounds easy? It isn't</h2>

*Every iteration takes time* of at least one person who must run queries, analyze the results and come up with a solution. It is not guaranteed that every proposed idea would be helpful in the long run. What's more, at some point a mistake, that pushes whole process into *wrong direction*, can be added. Spotting the impending danger is extramely hard, as sometimes it requires taking a few steps back in thinking and discarding previous work. 

Another thing is necessity to automatically perform and view a summary of the results. It is crucial to quickly check promising ideas before applying them on greater scale. Building a human-friendly interface may be time-consuming and not necessarily effective as people with background in tech and analysis are looking into different features. But even in the ideal world testing & understanding of every change will take *a lot of time and resources*.   

<h2>What is a solution?</h2>

Not surprisingly, you need an automatic system that do most of the work for you. Having some background in search engineering and machine learning I've come up with idea of **[genetic programming framework](https://github.com/mikolajkania/project-x)** doing exactly that. 

<h2>Genetic algorithms</h2>

Let me borrow [a simple definition](https://www.techopedia.com/definition/17137/genetic-algorithm): 
{% highlight text %}A genetic algorithm is a heuristic search method used in artificial intelligence and computing. It is used for finding optimized solutions to search problems based on the theory of natural selection and evolutionary biology. Genetic algorithms are excellent for searching through large and complex data sets. They are considered capable of finding reasonable solutions to complex issues as they are highly capable of solving unconstrained and constrained optimization issues.{% endhighlight %}

For those unfamiliar with concept of genetic programming I highly recommend a tutorial from this [site](https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_quick_guide.htm).

<h2>Why GA?</h2>

Why genetic programming is suitable for this type of problem? Putting aside the proven results of many experiments, the nature of our task also matches its applications.    

Firstly, it is easy to *define our problem as set of numeric weights* that can be altered during processing. Mutation, crossover & reproduction parts of the algorithm can easily be done on numbers. It's obvious, when you think about an individual of a population as a series of numbers, where every number is a weight of a document field (i.e. [5, 1, 5, 7, 10, 4, 3, 0]). Also evaluation function is trivial, it may be, for example, percentage of queries for which expected document returns on a top spot. 

Secondly, genetic algorithms are able to *preserve solutions that are promising*, even without actual understanding of a problem. Better species (individuals) will preserve and be an ancestors for even better ones.

Thirdly, due to mutation & crossover parts, algorithms *adds a bit of randomness to the process*. Every algorithm is prone to find a local minimum, that is a good but not the best solution. There may be a lot of correct answers and it is really hard for human to be sure if currently tested is one of them. But with random changes applied to the individuals genetic algorithm may catch on the trail.

Putting everything together it is clear, that genetic algorithm may be a good bet for these kind of problems.

<h2>Summary</h2>

In this post I described how the process of building the most basic search solution should look like. I have also presented why there is a need of automation in these area and proposed [my own project](https://github.com/mikolajkania/project-x) discovering optimal search weights. I hope you will find it interesting & helpful!